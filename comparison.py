import numpy as np
import matplotlib.pyplot as plt
import time
from tensorflow import keras
from tensorflow.keras import layers

# ============================================================================
# 1. CHARGEMENT ET PR√âPARATION DES DONN√âES
# ============================================================================

def load_data():
    """Charge et pr√©pare les donn√©es MNIST"""
    print("\n Chargement des donn√©es MNIST...")
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    

    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    

    y_train = keras.utils.to_categorical(y_train, 10)
    y_test = keras.utils.to_categorical(y_test, 10)
    
    print(f"‚úì Train: {x_train.shape}, Test: {x_test.shape}")
    return x_train, y_train, x_test, y_test


# ============================================================================
# 2. MOD√àLE CNN SIMPLE
# ============================================================================

def build_cnn():

    model = keras.Sequential([

        layers.Reshape((28, 28, 1), input_shape=(28, 28)),
        
        # Bloc 1
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # Bloc 2
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        
        # Classification
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(10, activation='softmax')
    ])

    print("## mod√©l CNN")
    model.summary()
    
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


# ============================================================================
# 3. MOD√àLE TRANSFORMER SIMPLE
# ============================================================================

def build_transformer():

    inputs = layers.Input(shape=(28, 28))
    

    x = layers.Dense(64)(inputs)
    
    
    attention = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)
    x = layers.Add()([x, attention])
    x = layers.LayerNormalization()(x)
    
    # Feed-forward
    ff = layers.Dense(128, activation='relu')(x)
    ff = layers.Dense(64)(ff)
    x = layers.Add()([x, ff])
    x = layers.LayerNormalization()(x)
    
    # Classification
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(10, activation='softmax')(x)
    
    model = keras.Model(inputs=inputs, outputs=outputs)
    
    print("## mod√©l transformer")
    model.summary()   

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model


# ============================================================================
# 4. ENTRA√éNEMENT
# ============================================================================

def train_model(model, x_train, y_train, x_test, y_test, model_name):
    """Entra√Æne un mod√®le et retourne les r√©sultats"""
    print(f"\n Entra√Ænement du mod√®le {model_name}...")
    print(f"Param√®tres: {model.count_params():,}")
    
    start_time = time.time()
    
    history = model.fit(
        x_train, y_train,
        validation_split=0.1,
        epochs=10,
        batch_size=128,
        verbose=1
    )
    
    training_time = time.time() - start_time
    
    # √âvaluation 
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    
    print(f"\n {model_name} termin√©:")
    print(f"  - Test Accuracy: {test_acc*100:.2f}%")
    print(f"  - Test Loss: {test_loss:.4f}")
    print(f"  - Temps d'entra√Ænement: {training_time:.1f}s")
    
    return {
        'history': history.history,
        'test_acc': test_acc,
        'test_loss': test_loss,
        'time': training_time,
        'params': model.count_params()
    }


# ============================================================================
# 5. VISUALISATION
# ============================================================================

def plot_comparison(cnn_results, trans_results):
    """Cr√©e des graphiques de comparaison"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # Accuracy pendant l'entra√Ænement
    ax = axes[0, 0]
    ax.plot(cnn_results['history']['accuracy'], 'b-', label='CNN Train', linewidth=2)
    ax.plot(cnn_results['history']['val_accuracy'], 'b--', label='CNN Val', linewidth=2)
    ax.plot(trans_results['history']['accuracy'], 'r-', label='Transformer Train', linewidth=2)
    ax.plot(trans_results['history']['val_accuracy'], 'r--', label='Transformer Val', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy')
    ax.set_title('Accuracy pendant l\'entra√Ænement')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Loss pendant l'entra√Ænement
    ax = axes[0, 1]
    ax.plot(cnn_results['history']['loss'], 'b-', label='CNN Train', linewidth=2)
    ax.plot(cnn_results['history']['val_loss'], 'b--', label='CNN Val', linewidth=2)
    ax.plot(trans_results['history']['loss'], 'r-', label='Transformer Train', linewidth=2)
    ax.plot(trans_results['history']['val_loss'], 'r--', label='Transformer Val', linewidth=2)
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Loss pendant l\'entra√Ænement')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Comparaison Test Accuracy
    ax = axes[1, 0]
    models = ['CNN', 'Transformer']
    accuracies = [cnn_results['test_acc']*100, trans_results['test_acc']*100]
    bars = ax.bar(models, accuracies, color=['#3498db', '#3498db'], alpha=0.7)
    ax.set_ylabel('Test Accuracy (%)')
    ax.set_title('Comparaison Test Accuracy')
    min_acc = min(accuracies) - 2
    ax.set_ylim([min_acc, 100])
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')
    
    # Comparaison Temps
    ax = axes[1, 1]
    times = [cnn_results['time'], trans_results['time']]
    bars = ax.bar(models, times, color=['#3498db', '#e74c3c'], alpha=0.7)
    ax.set_ylabel('Temps (secondes)')
    ax.set_title('Temps d\'entra√Ænement')
    for bar, t in zip(bars, times):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{t:.1f}s', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('comparison.png', dpi=300, bbox_inches='tight')
    print("\nüìä Graphique sauvegard√©: comparison.png")
    plt.show()


def print_summary(cnn_results, trans_results):
    """Affiche un tableau r√©capitulatif"""
    print("\n" + "="*60)
    print("üìä R√âSUM√â COMPARATIF")
    print("="*60)
    print(f"{'M√©trique':<25} {'CNN':<15} {'Transformer':<15}")
    print("-"*60)
    print(f"{'Test Accuracy':<25} {cnn_results['test_acc']*100:<15.2f} {trans_results['test_acc']*100:<15.2f}")
    print(f"{'Test Loss':<25} {cnn_results['test_loss']:<15.4f} {trans_results['test_loss']:<15.4f}")
    print(f"{'Training Time (s)':<25} {cnn_results['time']:<15.1f} {trans_results['time']:<15.1f}")
    print(f"{'Param√®tres':<25} {cnn_results['params']:<15,} {trans_results['params']:<15,}")
    print("="*60)
    
    # Meilleur mod√®le
    if cnn_results['test_acc'] > trans_results['test_acc']:
        print(f"\nüèÜ Meilleur mod√®le: CNN (+{(cnn_results['test_acc']-trans_results['test_acc'])*100:.2f}% accuracy)")
    else:
        print(f"\nüèÜ Meilleur mod√®le: Transformer (+{(trans_results['test_acc']-cnn_results['test_acc'])*100:.2f}% accuracy)")


# ============================================================================
# 6. MAIN - EX√âCUTION
# ============================================================================

def main():
    """Fonction principale"""
    print("="*60)
    print(" √âTUDE COMPARATIVE: CNN vs TRANSFORMER sur MNIST")
    print("="*60)
    
    # Charger les donn√©es
    x_train, y_train, x_test, y_test = load_data()
    
    # Entra√Æner CNN
    cnn = build_cnn()
    cnn_results = train_model(cnn, x_train, y_train, x_test, y_test, "CNN")
    
    # Entra√Æner Transformer
    transformer = build_transformer()
    trans_results = train_model(transformer, x_train, y_train, x_test, y_test, "Transformer")
    
    # Afficher les r√©sultats
    print_summary(cnn_results, trans_results)
    
    # Cr√©er les graphiques
    plot_comparison(cnn_results, trans_results)
    
    print("\n Comparaison termin√©e!")


if __name__ == "__main__":
    main()